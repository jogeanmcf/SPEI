{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download SPEI from COPERNICUS project\n",
    "\n",
    "Check the this [dataset](https://cds.climate.copernicus.eu/datasets/multi-origin-c3s-atlas?tab=overview) for mor infos, look for SPEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "dataset = \"multi-origin-c3s-atlas\"\n",
    "request = {\n",
    "    \"origin\": \"cmip6\",\n",
    "    \"experiment\": \"ssp5_8_5\",\n",
    "    \"domain\": \"global\",\n",
    "    \"period\": \"2015-2100\",\n",
    "    \"variable\": \"monthly_standardised_precipitation_evapotranspiration_index_for_6_months_cumulation_period\"\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "client.retrieve(dataset, request).download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download raw variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd ./data/historical/pr/wget_scripts/\n",
    "bash wget-20241228215607.sh -s\n",
    "bash wget-20241228225357.sh -s\n",
    "bash wget-20241228225701.sh -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd ./data/historical/tas/wget_scripts/\n",
    "bash wget-20241228220807.sh -s\n",
    "bash wget-20241228230852.sh -s\n",
    "bash wget-20241228230930.sh -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transform this into Enum, maybe?\n",
    "# EXPERIMENT = Literal['historical', 'ssp245', 'ssp126', 'ssp370', 'ssp585']\n",
    "# VARIABLE = Literal['pr', 'tas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'historical'\n",
    "variables = ['tas', 'pr']\n",
    "\n",
    "for variable in variables:\n",
    "    file_names = [file_name for file_name in os.listdir(f'./data/{experiment}/{variable}/wget_scripts/') if file_name.endswith('.nc')]\n",
    "    models = set([file_name.split('_')[2] for file_name in file_names])\n",
    "    for model in models:\n",
    "        _file_names = [file_name for file_name in file_names if model in file_name]\n",
    "        os.makedirs(f'./data/{experiment}/{variable}/{model}', exist_ok=True)\n",
    "        for file_name in _file_names:\n",
    "            os.system(f\"mv ./data/{experiment}/{variable}/wget_scripts/{file_name} ./data/{experiment}/{variable}/{model}/{file_name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking File Integrity and Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create scritp to check file ingetity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen({'time': 540, 'bnds': 2, 'lat': 256, 'lon': 512})\n",
      "Frozen({'time': 540, 'bnds': 2, 'lat': 324, 'lon': 432})\n",
      "Frozen({'time': 540, 'bnds': 2, 'lat': 192, 'lon': 288})\n"
     ]
    }
   ],
   "source": [
    "# checking datasets dimensions\n",
    "variable = 'pr'\n",
    "experiment = 'historical'  \n",
    "\n",
    "models = [folder_name for folder_name in os.listdir(f'./data/{experiment}/{variable}/') if 'wget_scripts' not in folder_name]\n",
    "models.sort()\n",
    "\n",
    "for model in models:\n",
    "    ds = xr.open_mfdataset(f'./data/{experiment}/{variable}/{model}/*.nc')\n",
    "    print(ds.sizes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen({'time': 540, 'bnds': 2, 'lat': 256, 'lon': 512})\n",
      "Frozen({'time': 540, 'bnds': 2, 'lat': 324, 'lon': 432})\n",
      "Frozen({'time': 540, 'bnds': 2, 'lat': 192, 'lon': 288})\n"
     ]
    }
   ],
   "source": [
    "# checking datasets dimensions\n",
    "variable = 'tas'\n",
    "models = [folder_name for folder_name in os.listdir(f'./data/{experiment}/{variable}/') if 'wget_scripts' not in folder_name]\n",
    "models.sort()\n",
    "\n",
    "for model in models:\n",
    "    ds = xr.open_mfdataset(f'./data/{experiment}/{variable}/{model}/*.nc')\n",
    "    print(ds.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spei-JrbXube1-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
